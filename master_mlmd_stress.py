# -*- coding: utf-8 -*-
"""master_mlmd_stress.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/10bNbV8mFLzdv4Xv4K7_8ZKw8o6WFudAH
"""

import h5py
import numpy as np
import matplotlib.pyplot as plt

from keras.models import Sequential
from keras.models import load_model
from keras.layers import Activation, Dense, Dropout
from keras import regularizers

cos  = np.cos 
sin  = np.sin
pi   = np.pi
sqrt = np.sqrt
acos = np.arccos

## parameters
rtt              = 0.1 # rate of training-testing
hidden_layers    = [100,75,50,25,12]
epochs           = 250
batch_size       = 512
verbose          = 1
validation_split = 0.01
shuffle          = True
optimizer        = 'adam'
activation_1st   = 'relu'
activation_hid   = 'relu'
activation_lst   = 'linear'
loss             = 'mean_squared_error'

## load scaled data
dict_scl = np.load('data_stress_scl.npy', allow_pickle=True)

datain            = dict_scl[0]['datain_scl']
dataou            = dict_scl[0]['dataou_scl']
radia_logarith_lb = dict_scl[0]['radia_logarith_lb']
radia_logarith_ub = dict_scl[0]['radia_logarith_ub']

dict_info = {'radia_logarith_lb':radia_logarith_lb,'radia_logarith_ub':radia_logarith_ub}
np.save('model_stress_info.npy',np.array([dict_info]))

## split data into train and test randomly
#  create random seed

np.random.seed(30)
num_data  = datain.shape[0]
ind_all   = np.random.permutation(num_data)
num_test  = np.int(np.floor(datain.shape[0]*rtt) )

ind_te    = ind_all[0:num_test]
ind_tr    = ind_all[num_test:]

datain_tr = datain[ind_tr] 
dataou_tr = dataou[ind_tr]
datain_te = datain[ind_te] 
dataou_te = dataou[ind_te]

## create the dense model
model = Sequential()
model.add(Dense(hidden_layers[0], input_dim=datain_tr.shape[1], activation=activation_1st))
for l0 in hidden_layers[1:]:
  model.add(Dense(l0, activation=activation_hid, kernel_regularizer=regularizers.l2(0)))
model.add(Dense(dataou_tr.shape[1], activation=activation_lst))
model.compile(loss=loss, optimizer=optimizer)

## train and save the mdoel
history     = model.fit(datain_tr, dataou_tr, epochs=epochs, batch_size=batch_size, verbose=verbose, shuffle=shuffle, validation_split=validation_split)
model.save('model_stress.h5')

## test the model
dataes_tr = model.predict(datain_tr)
dataes_te = model.predict(datain_te)

## get loss information
loss_tr   = np.log10(np.array(history.history['loss']))
loss_vl   = np.log10(np.array(history.history['val_loss']))

## make some plots
# make estimation ready for plots
trou = np.reshape(dataou_tr,(dataou_tr.shape[0]*dataou_tr.shape[1],1))
tres = np.reshape(dataes_tr,(dataes_tr.shape[0]*dataes_tr.shape[1],1))
teou = np.reshape(dataou_te,(dataou_te.shape[0]*dataou_te.shape[1],1)) 
tees = np.reshape(dataes_te,(dataes_te.shape[0]*dataes_te.shape[1],1))

fig, axs = plt.subplots(1, 3,figsize=(18,6))

axs[0].plot(np.array(range(epochs))+1,loss_tr,'-', label='train');
axs[0].plot(np.array(range(epochs))+1,loss_vl,'--', label='validation');
axs[0].set_title('epoch vs training and validation loss');
axs[0].set_xlabel('epoch');
axs[0].set_ylabel('standard logarithm of mse');
axs[0].legend(loc='upper right', shadow=True);

axs[1].plot(trou, tres, '*',markersize = 1, label = 'output data');
axs[1].plot([-1,1],[-1,1],linewidth = 5, label = 'bisector');
axs[1].set_title('training real vs estimate');
axs[1].set_xlabel('real');
axs[1].set_ylabel('estimate');
axs[1].legend(loc='upper left', shadow=True);

axs[2].plot(teou, tees, '*',markersize = 1, label = 'output data');
axs[2].plot([-1,1],[-1,1],linewidth = 5, label = 'bisector');
axs[2].set_title('testing real vs estimate');
axs[2].set_xlabel('real');
axs[2].set_ylabel('estimate');
axs[2].legend(loc='upper left', shadow=True);

filename = 'stress_trainin_testing_plots.png'
plt.savefig(filename, dpi=600)